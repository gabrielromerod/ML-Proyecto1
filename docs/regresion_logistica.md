# Regresi贸n log铆stica - Clasificaci贸n de Mariposas  

Parte del proyecto de clasificaci贸n de mariposas consiste en la implementaci贸n de un modelo de regresi贸n log铆stica.

La regresi贸n log铆stica es un algoritmo de aprendizaje supervisado utilizado principalmente para problemas de clasificaci贸n binaria, aunque tambi茅n se puede extender a problemas de clasificaci贸n multiclase.
# Funcionamiento de la Regresi贸n Log铆stica:

## hiperplano
$h(x_i) = w_0*x_0 + w_1 * x_1 + ... +w_n*x_n$

Donde: 
- $w_0$ es el bias
- $w_1$ es el peso de la primera caracter铆stica
- $x_1$ es la primera caracter铆stica
- $n$ es el n煤mero de caracter铆sticas

El hiperplano es la frontera de decisi贸n que separa las clases. Nos sirve para poder clasificar los datos.

## Hip贸tesis
$s(x_i) = \frac{1}{1+e^{-h(x_i)}}$

Donde:
- $s(x_i)$ es la hip贸tesis
- $h(x_i)$ es el hiperplano

Esta funci贸n se conoce como funci贸n sigmoide o log铆stica. Esta funci贸n toma valores de -infinito a infinito y los transforma en valores entre 0 y 1.

## Loss Function
![Loss Function](/docs/assets/Loss_function_graphic.png)
$L = -\sum_{i=1}^{n}[y_i*log(s(x_i))+(1-y_i)*log(1-s(x_i))]$

Nos sirve para calcular que tan bien est谩 aprendiendo nuestro modelo. Si el valor de y es 1 y el modelo est谩 aprendiendo bien, el valor de la funci贸n de p茅rdida ser谩 bajo. Si el modelo no est谩 aprendiendo bien, el valor de la funci贸n de p茅rdida ser谩 alto. De manera similar pero inversa funciona cuando el valor de y es 0.

## Derivadas
$\frac{\partial L}{\partial w_j} =\frac{1}{n} \sum_{i=1}^{n}(y_i - s(x_i))*(-x_{ij})$

El uso de las derivadas nos sirve para poder actualizar los pesos y el bias de nuestro modelo.

# Aplicaciones de la Regresi贸n Log铆stica:

La regresi贸n log铆stica se utiliza en una amplia variedad de aplicaciones, incluyendo:

**Diagn贸stico M茅dico:** Por ejemplo, para predecir si un paciente tiene una enfermedad o no en funci贸n de sus s铆ntomas y resultados de pruebas.

**Detecci贸n de Spam:** Para clasificar correos electr贸nicos como spam o no spam en funci贸n de su contenido y caracter铆sticas.

**Cr茅dito y Evaluaci贸n de Riesgos:** Para determinar si un solicitante de cr茅dito es un riesgo crediticio o no, bas谩ndose en sus antecedentes financieros.

**Marketing:** Para predecir si un cliente comprar谩 un producto o responder谩 a una campa帽a de marketing.

**An谩lisis de Sentimientos:** Para analizar opiniones de usuarios y clasificarlas como positivas o negativas.

# Limitaciones de la Regresi贸n Log铆stica:

**Linealidad:** La regresi贸n log铆stica asume una relaci贸n lineal entre las caracter铆sticas y la probabilidad logar铆tmica. Puede tener dificultades para modelar relaciones m谩s complejas entre las variables.

**Suposici贸n de Independencia:** Supone que las observaciones son independientes entre s铆, lo que puede no ser cierto en todos los casos, como en datos de series temporales.

**No es adecuada para Clasificaci贸n Multiclase:** Aunque se puede extender para clasificaci贸n multiclase (usando t茅cnicas como la regresi贸n log铆stica multinomial o la regresi贸n log铆stica ordinal), existen algoritmos espec铆ficos para esta tarea que pueden ser m谩s eficientes.

**Sensible a Datos Desbalanceados:** Si las clases est谩n desequilibradas en t茅rminos de cantidad de datos, la regresi贸n log铆stica puede sesgarse hacia la clase dominante.

**No maneja bien datos faltantes:** La regresi贸n log铆stica asume que los datos est谩n completos y puede no manejar adecuadamente los valores faltantes

## Implementaci贸n de la regresi贸n log铆stica

El uso de clases fue predominante en nuestra propia versi贸n de la regresi贸n log铆stica. Para ello, se crearon tres clases: `Rlogistica`, `Training`y `Testing`.

### Clase Rlogistica
La clase `Rlogistica` es la encargada de encapsular el funcionamientode la regresi贸n logistica. Se inicializa con tres argumentos: `x`, `y` y `alpha`, que representan las caracter铆sticas, las etiquetas y la tasa de aprendizaje, respectivamente.
```python
class Rlogistica:
    def __init__(self, x, y=0, alpha=0):
        self.x = x
        self.y = y
        self.alpha = alpha

    def Hiperplano(self, w):
        return np.dot(self.x, w)

    def S(self, w):
        result = 1 / (1 + np.exp((-1) * self.Hiperplano(w)))  # write your code here
        return result

    def Loss_function(self, w):
        n = len(self.y)
        A = self.y * np.log(self.S(w))
        B = (1 - self.y) * np.log(1 - self.S(w))
        C = np.sum(A + B)
        loss = (-1 / n) * C
        return loss

    def Derivatives(self, w):
        n = len(self.y)
        s_x = self.S(w)
        error = self.y - s_x
        D = -np.dot(error, self.x) / n
        return D

    def change_parameters(self, derivatives, w):
        return w - self.alpha * derivatives
```
El m茅todo `Hiperplano` representa la funci贸n matem谩tica del hiperplano para obtener las predicciones. El m茅todo `S` representa la funci贸n sigmoide. El m茅todo `Loss_function` representa la funci贸n de p茅rdida. El m茅todo `Derivatives` representa las derivadas de la funci贸n de p茅rdida. Finalmente, el m茅todo `change_parameters` actualiza los pesos del modelo.

### Clase Training
La clase `Training` es la responsable de entrenar el modelo de regresi贸n log铆stica en el dataset de mariposas. Se inicializa con tres argumentos: `x_train`, `y_train`, `alpha` y `epochs`, que representan las caracter铆sticas de entrenamiento, las etiquetas de entrenamiento, la tasa de aprendizaje y la cantidad de veces que se entrena el modelo, respectivamente. La clase utiliza una instancia de la clase `Rlogistica` para calcular las predicciones, 

```python
class Training:
    def __init__(self, x_trian, y_train, epochs, alpha):
        self.Rlogistica = Rlogistica(x_trian, y_train, alpha)
        self.epochs = epochs

    def startT(self):
        loss = []
        w = np.ones(self.Rlogistica.x.shape[1])
        for i in range(self.epochs):
            L = self.Rlogistica.Loss_function(w)
            dw = self.Rlogistica.Derivatives(w)
            w = self.Rlogistica.change_parameters(dw, w)
            loss.append(L)

        return w, loss
```
El m茅todo `startT` entrena el modelo de regresi贸n log铆stica. Para ello, inicializa los pesos del modelo en 1 y, posteriormente, actualiza los pesos `epochs` veces. Finalmente, retorna los pesos y la lista de p茅rdidas.
### Clase `Testing`

La clase `Testing` es la responsable de evaluar el rendimiento del modelo de regresi贸n log铆stica en el dataset de mariposas. Se inicializa con tres argumentos: `x_test`, `y_test` y `w`, que representan las caracter铆sticas de prueba, las etiquetas de prueba y los pesos del modelo, respectivamente. La clase utiliza una instancia de la clase `Rlogistica` para calcular las predicciones, `y_pred`, utilizando la funci贸n sigmoide, `S`.

```python
class Testing:
    def __init__(self, x_test, y_test, w):
        self.x_test = x_test
        self.y_test = y_test
        self.w = w
        self.logist = Rlogistica(x_test, y_test, 0)

    def Testing(self):
        n = len(self.y_test)
        y_pred = self.logist.S(self.w)
        y_pred = np.round(y_pred)
        correct = np.sum(y_pred == self.y_test)
        print(f"N煤mero de datos correctos: {correct}")
        accuracy = (correct / n) * 100
        print(f"Porcentaje de aciertos: {accuracy}%")
        print(f"Porcentaje de fallas: {100 - accuracy}%")
```

El m茅todo `Testing` calcula el n煤mero de predicciones correctas comparando `y_pred` con `y_test` y, posteriormente, calcula la precisi贸n del modelo. Finalmente, imprime el n煤mero de aciertos, el porcentaje de aciertos y el porcentaje de fallas.